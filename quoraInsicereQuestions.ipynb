{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "quoraInsicereQuestions.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nhAnik/MlProject/blob/master/quoraInsicereQuestions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "42015lXlRotI",
        "colab_type": "code",
        "outputId": "c394dd05-65ed-4b1a-fe4a-2c2e663a84d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.840B.300d.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-02-07 04:46:50--  http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.840B.300d.zip [following]\n",
            "--2019-02-07 04:46:50--  https://nlp.stanford.edu/data/glove.840B.300d.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2176768927 (2.0G) [application/zip]\n",
            "Saving to: ‘glove.840B.300d.zip’\n",
            "\n",
            "glove.840B.300d.zip 100%[===================>]   2.03G  26.8MB/s    in 92s     \n",
            "\n",
            "2019-02-07 04:48:22 (22.6 MB/s) - ‘glove.840B.300d.zip’ saved [2176768927/2176768927]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IGnQ5Nt1Sfis",
        "colab_type": "code",
        "outputId": "dabe9021-c78a-42af-9cee-92bf8313a3f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PIMyHG3oS-Au",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zipRef=zipfile.ZipFile('glove.840B.300d.zip','r')\n",
        "zipRef.extractall()\n",
        "zipRef.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gRrb5rmSTEA7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "from tqdm import tqdm\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2YVZrNn3TCFh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "trainDf=pd.read_csv(\"/content/gdrive/My Drive/colabData/MlProject/train.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DPfciCPMTORr",
        "colab_type": "code",
        "outputId": "044c70cd-92d8-4e12-8721-d319c7b5f7d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "def readEmbeddings(embeddingsFile):\n",
        "    \n",
        "    tempDict={}\n",
        "    f=open(embeddingsFile)\n",
        "    for line in tqdm(f):\n",
        "        values=line.split(\" \")\n",
        "        word=values[0]\n",
        "        vect=np.asarray(values[1:],dtype='float32')\n",
        "        tempDict[word]=vect\n",
        "    f.close()\n",
        "   \n",
        "    return tempDict\n",
        "embeddingsDict=readEmbeddings('glove.840B.300d.txt')\n",
        "\n",
        "vectDim=300\n",
        "numOfVect=30"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2196017it [02:50, 12847.31it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "FHHaJcbFUeRu",
        "colab_type": "code",
        "outputId": "4e011e35-744a-4ead-a5fe-d87d36783182",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "trainDf, valDf = train_test_split(trainDf, test_size=0.4)\n",
        "valDf, testDf = train_test_split(valDf, test_size=0.5)\n",
        "print(trainDf.shape)\n",
        "print(testDf.shape)\n",
        "print(valDf.shape) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(783673, 3)\n",
            "(261225, 3)\n",
            "(261224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3ggqUwN2UkFQ",
        "colab_type": "code",
        "outputId": "4c1c702d-0d0f-4540-9cd2-f458926129ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "def textToArr(txt):\n",
        "    zeroVect=np.zeros(vectDim)\n",
        "    txt=txt[:-1].split()[:numOfVect]\n",
        "    embeds=[embeddingsDict.get(x,zeroVect) for x in txt]\n",
        "    embeds+=[zeroVect]*(numOfVect-len(embeds)) \n",
        "    return np.array(embeds)\n",
        "\n",
        "textToArr(\"what is quora?\").shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "ML4sTOMGUoB0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batchSize = 128\n",
        "\n",
        "def batchGenerate(train_df):\n",
        "    numBatches = math.ceil(len(train_df) / batchSize)\n",
        "    while True: \n",
        "        train_df = train_df.sample(frac=1.)   \n",
        "        for i in range(numBatches):\n",
        "            texts = train_df.iloc[i*batchSize:(i+1)*batchSize, 1]\n",
        "            textArr = np.array([textToArr(text) for text in texts])\n",
        "            yield textArr, np.array(train_df[\"target\"][i*batchSize:(i+1)*batchSize])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ef3aDVICUwaR",
        "colab_type": "code",
        "outputId": "431ac725-16ba-4b39-8567-281bfa68cdc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def recall(y_true, y_pred): \n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "      \n",
        "def precision(y_true, y_pred): \n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "    prec = precision(y_true, y_pred)\n",
        "    rec = recall(y_true, y_pred)\n",
        "    return 2*((prec*rec)/(prec+rec+K.epsilon()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "imKr8uKUUrMz",
        "colab_type": "code",
        "outputId": "82e36e7a-079f-44b4-f267-8f1c95321554",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import CuDNNLSTM, Dense, Bidirectional, Dropout\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Bidirectional(CuDNNLSTM(64, return_sequences=True), input_shape=(30, 300))) \n",
        "model.add(Bidirectional(CuDNNLSTM(64)))  \n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',recall,precision,f1])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bidirectional_5 (Bidirection (None, 30, 128)           187392    \n",
            "_________________________________________________________________\n",
            "bidirectional_6 (Bidirection (None, 128)               99328     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 286,849\n",
            "Trainable params: 286,849\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qcjdsE3XUtmy",
        "colab_type": "code",
        "outputId": "1008b6a2-19ad-4abe-dd93-8beed8923bbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "cell_type": "code",
      "source": [
        "trainGen = batchGenerate(trainDf)\n",
        "valGen=batchGenerate(valDf)\n",
        "model.fit_generator(trainGen, epochs=10, steps_per_epoch=4000, validation_data=valGen, validation_steps=2000, verbose=True) "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "4000/4000 [==============================] - 225s 56ms/step - loss: 0.1207 - acc: 0.9529 - recall: 0.4660 - precision: 0.6630 - f1: 0.5213 - val_loss: 0.1121 - val_acc: 0.9553 - val_recall: 0.6014 - val_precision: 0.6499 - val_f1: 0.6081\n",
            "Epoch 2/10\n",
            "4000/4000 [==============================] - 224s 56ms/step - loss: 0.1067 - acc: 0.9577 - recall: 0.5512 - precision: 0.6999 - f1: 0.5952 - val_loss: 0.1078 - val_acc: 0.9577 - val_recall: 0.5139 - val_precision: 0.7233 - val_f1: 0.5813\n",
            "Epoch 3/10\n",
            "4000/4000 [==============================] - 227s 57ms/step - loss: 0.1022 - acc: 0.9595 - recall: 0.5770 - precision: 0.7133 - f1: 0.6166 - val_loss: 0.1056 - val_acc: 0.9583 - val_recall: 0.5945 - val_precision: 0.6907 - val_f1: 0.6206\n",
            "Epoch 4/10\n",
            "4000/4000 [==============================] - 230s 58ms/step - loss: 0.0960 - acc: 0.9616 - recall: 0.6131 - precision: 0.7291 - f1: 0.6474 - val_loss: 0.1046 - val_acc: 0.9586 - val_recall: 0.6282 - val_precision: 0.6808 - val_f1: 0.6367\n",
            "Epoch 5/10\n",
            "4000/4000 [==============================] - 230s 58ms/step - loss: 0.0913 - acc: 0.9634 - recall: 0.6294 - precision: 0.7330 - f1: 0.6588 - val_loss: 0.1087 - val_acc: 0.9587 - val_recall: 0.6096 - val_precision: 0.6905 - val_f1: 0.6315\n",
            "Epoch 6/10\n",
            "4000/4000 [==============================] - 229s 57ms/step - loss: 0.0885 - acc: 0.9643 - recall: 0.6506 - precision: 0.7399 - f1: 0.6739 - val_loss: 0.1043 - val_acc: 0.9593 - val_recall: 0.5790 - val_precision: 0.7102 - val_f1: 0.6195\n",
            "Epoch 7/10\n",
            "4000/4000 [==============================] - 229s 57ms/step - loss: 0.0803 - acc: 0.9678 - recall: 0.6930 - precision: 0.7615 - f1: 0.7092 - val_loss: 0.1095 - val_acc: 0.9577 - val_recall: 0.6277 - val_precision: 0.6730 - val_f1: 0.6330\n",
            "Epoch 8/10\n",
            "4000/4000 [==============================] - 228s 57ms/step - loss: 0.0769 - acc: 0.9690 - recall: 0.7126 - precision: 0.7725 - f1: 0.7258 - val_loss: 0.1172 - val_acc: 0.9574 - val_recall: 0.6432 - val_precision: 0.6620 - val_f1: 0.6363\n",
            "Epoch 9/10\n",
            "4000/4000 [==============================] - 230s 58ms/step - loss: 0.0728 - acc: 0.9704 - recall: 0.7295 - precision: 0.7757 - f1: 0.7370 - val_loss: 0.1168 - val_acc: 0.9558 - val_recall: 0.6151 - val_precision: 0.6556 - val_f1: 0.6165\n",
            "Epoch 10/10\n",
            "4000/4000 [==============================] - 230s 58ms/step - loss: 0.0644 - acc: 0.9742 - recall: 0.7736 - precision: 0.8019 - f1: 0.7743 - val_loss: 0.1251 - val_acc: 0.9553 - val_recall: 0.6145 - val_precision: 0.6472 - val_f1: 0.6144\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faa047cc400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "FBLtLSYnVmp1",
        "colab_type": "code",
        "outputId": "ce9b554d-24fa-4e2a-b0df-6bb17e9d98b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "testGen=batchGenerate(testDf)\n",
        "score = model.evaluate_generator(testGen, steps=2000, verbose=1)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000/2000 [==============================] - 36s 18ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lZ5uOZAtVnbo",
        "colab_type": "code",
        "outputId": "3f7fd254-bf46-4412-e3f3-55a485b70805",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "cell_type": "code",
      "source": [
        "print(model.metrics_names[0],\":\",score[0])\n",
        "print(model.metrics_names[1],\":\",score[1])\n",
        "print(model.metrics_names[2],\":\",score[2])\n",
        "print(model.metrics_names[3],\":\",score[3])\n",
        "print(model.metrics_names[4],\":\",score[4])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss : 0.1257426714557223\n",
            "acc : 0.95458203125\n",
            "recall : 0.6159595116488635\n",
            "precision : 0.6395830409601331\n",
            "f1 : 0.6101039763465523\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}